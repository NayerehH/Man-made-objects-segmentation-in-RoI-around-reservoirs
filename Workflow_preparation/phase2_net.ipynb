{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Nb2fISsnze"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZf_BZ54snzi",
        "outputId": "b521a8e9-8674-4008-cd47-024f4feccd22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'tf.keras'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import albumentations as A\n",
        "import glob\n",
        "import segmentation_models as sm\n",
        "from skimage import measure\n",
        "from sklearn.metrics import classification_report\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "190Nh2fVsnzm",
        "outputId": "c2b9a587-e5c8-4896-a136-b246852d37a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 17% |\n",
            "|  1 |  0% | 17% |\n",
            "|  2 |  0% |  0% |\n",
            "|  3 |  0% |  0% |\n"
          ]
        }
      ],
      "source": [
        "import GPUtil\n",
        "import psutil\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
        "\n",
        "GPUtil.showUtilization()\n",
        "psutil.cpu_percent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alAigOT7snzp"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyzvF6F8snzr"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = './net2_data/'\n",
        "\n",
        "x_train_dir = os.path.join(DATA_DIR, 'train_rgb_70/')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train_anno_70/')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'test_rgb_30/')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'test_anno_30/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVKY9FMFsnzt"
      },
      "outputs": [],
      "source": [
        "\n",
        "def visualize(**images):\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def denormalize(x):\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)\n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x\n",
        "\n",
        "\n",
        "# classes for data loading and preprocessing\n",
        "class Dataset:\n",
        "\n",
        "\n",
        "    CLASSES = ['nonmanmade', 'manmade']\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            images_dir,\n",
        "            masks_dir,\n",
        "            classes=None,\n",
        "            augmentation=None,\n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.ids = os.listdir(images_dir)\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
        "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
        "\n",
        "        # convert str names to class values on masks\n",
        "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
        "\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.masks_fps[i], 0)\n",
        "\n",
        "        # extract certain classes from mask\n",
        "        masks = [(mask == v) for v in self.class_values]\n",
        "        mask = np.stack(masks, axis=-1).astype('float')\n",
        "\n",
        "        # add background if mask is not binary\n",
        "        if mask.shape[-1] != 1:\n",
        "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
        "            mask = np.concatenate((mask, background), axis=-1)\n",
        "\n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "\n",
        "class Dataloder(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(dataset))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        # collect batch data\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        # transpose list of lists\n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "\n",
        "        if self.shuffle:\n",
        "            self.indexes = np.random.permutation(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAlQmXpwsnzw"
      },
      "outputs": [],
      "source": [
        "def round_clip_0_1(x, **kwargs):\n",
        "    return x.round().clip(0, 1)\n",
        "\n",
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        A.HorizontalFlip(p=0.7),\n",
        "        A.VerticalFlip(p=0.7),\n",
        "\n",
        "\n",
        "        A.Lambda(mask=round_clip_0_1)\n",
        "    ]\n",
        "    return A.Compose(train_transform)\n",
        "\n",
        "def get_validation_augmentation():\n",
        "\n",
        "    test_transform = [\n",
        "        A.PadIfNeeded(384, 384)\n",
        "    ]\n",
        "    return A.Compose(test_transform)\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "\n",
        "\n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "    ]\n",
        "    return A.Compose(_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqB_xVgRsnzx"
      },
      "source": [
        "# vgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgpfZfKasnzy"
      },
      "outputs": [],
      "source": [
        "# define network parameters\n",
        "BACKBONE = 'vgg16'\n",
        "BATCH_SIZE = 8\n",
        "CLASSES = [ 'manmade']\n",
        "LR = 0.0001\n",
        "EPOCHS = 80\n",
        "n_classes = 1\n",
        "activation = 'sigmoid'\n",
        "\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "#create model\n",
        "model = sm.FPN(BACKBONE, classes=n_classes, activation=activation,encoder_weights='imagenet',pyramid_dropout=0.3)\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=np.array([1,1]))\n",
        "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
        "\n",
        "model.compile(optim, total_loss, metrics)\n",
        "\n",
        "model_name = './net2_fpn.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1OqzmEksnz0",
        "outputId": "0a9366a7-5816-4f7c-acec-eba42d6c2e49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nayereh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "1032/1032 [==============================] - 712s 678ms/step - loss: 0.4450 - iou_score: 0.4920 - f1-score: 0.6440 - val_loss: 0.6796 - val_iou_score: 0.5579 - val_f1-score: 0.6341 - lr: 1.0000e-04\n",
            "Epoch 2/80\n",
            "1032/1032 [==============================] - 711s 689ms/step - loss: 0.3270 - iou_score: 0.5616 - f1-score: 0.7097 - val_loss: 0.6778 - val_iou_score: 0.6324 - val_f1-score: 0.7071 - lr: 1.0000e-04\n",
            "Epoch 3/80\n",
            "1032/1032 [==============================] - 718s 695ms/step - loss: 0.3067 - iou_score: 0.5821 - f1-score: 0.7269 - val_loss: 0.6626 - val_iou_score: 0.6342 - val_f1-score: 0.7076 - lr: 1.0000e-04\n",
            "Epoch 4/80\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.2923 - iou_score: 0.5969 - f1-score: 0.7394 - val_loss: 0.6635 - val_iou_score: 0.6040 - val_f1-score: 0.6782 - lr: 1.0000e-04\n",
            "Epoch 5/80\n",
            "1032/1032 [==============================] - 725s 702ms/step - loss: 0.2836 - iou_score: 0.6062 - f1-score: 0.7472 - val_loss: 0.6646 - val_iou_score: 0.6483 - val_f1-score: 0.7207 - lr: 1.0000e-04\n",
            "Epoch 6/80\n",
            "1032/1032 [==============================] - 725s 702ms/step - loss: 0.2836 - iou_score: 0.6063 - f1-score: 0.7470 - val_loss: 0.6737 - val_iou_score: 0.6566 - val_f1-score: 0.7262 - lr: 1.0000e-04\n",
            "Epoch 7/80\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.2689 - iou_score: 0.6222 - f1-score: 0.7599 - val_loss: 0.6632 - val_iou_score: 0.6680 - val_f1-score: 0.7378 - lr: 1.0000e-04\n",
            "Epoch 8/80\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 0.2664 - iou_score: 0.6249 - f1-score: 0.7620\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.2664 - iou_score: 0.6249 - f1-score: 0.7620 - val_loss: 0.6770 - val_iou_score: 0.6612 - val_f1-score: 0.7317 - lr: 1.0000e-04\n",
            "Epoch 9/80\n",
            "1032/1032 [==============================] - 727s 704ms/step - loss: 0.2446 - iou_score: 0.6497 - f1-score: 0.7816 - val_loss: 0.6486 - val_iou_score: 0.6692 - val_f1-score: 0.7414 - lr: 2.0000e-05\n",
            "Epoch 10/80\n",
            "1032/1032 [==============================] - 726s 704ms/step - loss: 0.2372 - iou_score: 0.6581 - f1-score: 0.7881 - val_loss: 0.6494 - val_iou_score: 0.6793 - val_f1-score: 0.7505 - lr: 2.0000e-05\n",
            "Epoch 11/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2314 - iou_score: 0.6642 - f1-score: 0.7934 - val_loss: 0.6614 - val_iou_score: 0.6781 - val_f1-score: 0.7499 - lr: 2.0000e-05\n",
            "Epoch 12/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2292 - iou_score: 0.6674 - f1-score: 0.7955 - val_loss: 0.6444 - val_iou_score: 0.6753 - val_f1-score: 0.7470 - lr: 2.0000e-05\n",
            "Epoch 13/80\n",
            "1032/1032 [==============================] - 724s 701ms/step - loss: 0.2236 - iou_score: 0.6738 - f1-score: 0.8006 - val_loss: 0.6496 - val_iou_score: 0.6836 - val_f1-score: 0.7551 - lr: 2.0000e-05\n",
            "Epoch 14/80\n",
            "1032/1032 [==============================] - 726s 704ms/step - loss: 0.2212 - iou_score: 0.6766 - f1-score: 0.8027 - val_loss: 0.6449 - val_iou_score: 0.6780 - val_f1-score: 0.7499 - lr: 2.0000e-05\n",
            "Epoch 15/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2178 - iou_score: 0.6808 - f1-score: 0.8058 - val_loss: 0.6469 - val_iou_score: 0.6731 - val_f1-score: 0.7455 - lr: 2.0000e-05\n",
            "Epoch 16/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2151 - iou_score: 0.6840 - f1-score: 0.8082 - val_loss: 0.6556 - val_iou_score: 0.6857 - val_f1-score: 0.7560 - lr: 2.0000e-05\n",
            "Epoch 17/80\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 0.2137 - iou_score: 0.6860 - f1-score: 0.8096\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.2137 - iou_score: 0.6860 - f1-score: 0.8096 - val_loss: 0.6541 - val_iou_score: 0.6816 - val_f1-score: 0.7522 - lr: 2.0000e-05\n",
            "Epoch 18/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2079 - iou_score: 0.6930 - f1-score: 0.8148 - val_loss: 0.6473 - val_iou_score: 0.6829 - val_f1-score: 0.7541 - lr: 4.0000e-06\n",
            "Epoch 19/80\n",
            "1032/1032 [==============================] - 727s 704ms/step - loss: 0.2059 - iou_score: 0.6957 - f1-score: 0.8167 - val_loss: 0.6452 - val_iou_score: 0.6817 - val_f1-score: 0.7535 - lr: 4.0000e-06\n",
            "Epoch 20/80\n",
            "1032/1032 [==============================] - 727s 705ms/step - loss: 0.2047 - iou_score: 0.6971 - f1-score: 0.8178 - val_loss: 0.6443 - val_iou_score: 0.6837 - val_f1-score: 0.7555 - lr: 4.0000e-06\n",
            "Epoch 21/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2037 - iou_score: 0.6984 - f1-score: 0.8188 - val_loss: 0.6487 - val_iou_score: 0.6851 - val_f1-score: 0.7566 - lr: 4.0000e-06\n",
            "Epoch 22/80\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.2025 - iou_score: 0.6999 - f1-score: 0.8199 - val_loss: 0.6500 - val_iou_score: 0.6836 - val_f1-score: 0.7548 - lr: 4.0000e-06\n",
            "Epoch 23/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2023 - iou_score: 0.7002 - f1-score: 0.8201 - val_loss: 0.6485 - val_iou_score: 0.6811 - val_f1-score: 0.7526 - lr: 4.0000e-06\n",
            "Epoch 24/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2013 - iou_score: 0.7015 - f1-score: 0.8210 - val_loss: 0.6458 - val_iou_score: 0.6814 - val_f1-score: 0.7531 - lr: 4.0000e-06\n",
            "Epoch 25/80\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 0.2007 - iou_score: 0.7022 - f1-score: 0.8216\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.2007 - iou_score: 0.7022 - f1-score: 0.8216 - val_loss: 0.6498 - val_iou_score: 0.6833 - val_f1-score: 0.7547 - lr: 4.0000e-06\n",
            "Epoch 26/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.1993 - iou_score: 0.7039 - f1-score: 0.8227 - val_loss: 0.6487 - val_iou_score: 0.6822 - val_f1-score: 0.7535 - lr: 8.0000e-07\n",
            "Epoch 27/80\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.1985 - iou_score: 0.7049 - f1-score: 0.8235 - val_loss: 0.6472 - val_iou_score: 0.6808 - val_f1-score: 0.7523 - lr: 8.0000e-07\n",
            "Epoch 28/80\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.1987 - iou_score: 0.7049 - f1-score: 0.8235 - val_loss: 0.6491 - val_iou_score: 0.6813 - val_f1-score: 0.7526 - lr: 8.0000e-07\n",
            "Epoch 29/80\n",
            "1032/1032 [==============================] - 725s 702ms/step - loss: 0.1984 - iou_score: 0.7051 - f1-score: 0.8236 - val_loss: 0.6489 - val_iou_score: 0.6813 - val_f1-score: 0.7527 - lr: 8.0000e-07\n",
            "Epoch 30/80\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 0.1981 - iou_score: 0.7055 - f1-score: 0.8239\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
            "1032/1032 [==============================] - 725s 703ms/step - loss: 0.1981 - iou_score: 0.7055 - f1-score: 0.8239 - val_loss: 0.6485 - val_iou_score: 0.6817 - val_f1-score: 0.7530 - lr: 8.0000e-07\n",
            "Epoch 31/80\n",
            "1032/1032 [==============================] - 726s 703ms/step - loss: 0.1979 - iou_score: 0.7058 - f1-score: 0.8241 - val_loss: 0.6483 - val_iou_score: 0.6814 - val_f1-score: 0.7528 - lr: 1.6000e-07\n",
            "Epoch 32/80\n",
            "1032/1032 [==============================] - 727s 705ms/step - loss: 0.1979 - iou_score: 0.7058 - f1-score: 0.8242 - val_loss: 0.6484 - val_iou_score: 0.6819 - val_f1-score: 0.7532 - lr: 1.6000e-07\n",
            "Epoch 33/80\n",
            "1032/1032 [==============================] - 728s 705ms/step - loss: 0.1977 - iou_score: 0.7060 - f1-score: 0.8243 - val_loss: 0.6485 - val_iou_score: 0.6812 - val_f1-score: 0.7526 - lr: 1.6000e-07\n",
            "Epoch 34/80\n",
            "1032/1032 [==============================] - 728s 705ms/step - loss: 0.1980 - iou_score: 0.7057 - f1-score: 0.8241 - val_loss: 0.6480 - val_iou_score: 0.6809 - val_f1-score: 0.7523 - lr: 1.6000e-07\n",
            "Epoch 35/80\n",
            "1032/1032 [==============================] - ETA: 0s - loss: 0.1972 - iou_score: 0.7067 - f1-score: 0.8248\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "1032/1032 [==============================] - 728s 705ms/step - loss: 0.1972 - iou_score: 0.7067 - f1-score: 0.8248 - val_loss: 0.6486 - val_iou_score: 0.6820 - val_f1-score: 0.7534 - lr: 1.6000e-07\n",
            "Epoch 36/80\n",
            "1032/1032 [==============================] - 728s 705ms/step - loss: 0.1976 - iou_score: 0.7062 - f1-score: 0.8244 - val_loss: 0.6484 - val_iou_score: 0.6818 - val_f1-score: 0.7531 - lr: 1.0000e-07\n",
            "Epoch 37/80\n",
            "1032/1032 [==============================] - 728s 706ms/step - loss: 0.1976 - iou_score: 0.7062 - f1-score: 0.8244 - val_loss: 0.6488 - val_iou_score: 0.6824 - val_f1-score: 0.7537 - lr: 1.0000e-07\n",
            "Epoch 38/80\n",
            "1032/1032 [==============================] - 729s 706ms/step - loss: 0.1976 - iou_score: 0.7062 - f1-score: 0.8244 - val_loss: 0.6488 - val_iou_score: 0.6815 - val_f1-score: 0.7528 - lr: 1.0000e-07\n",
            "Epoch 39/80\n",
            "1032/1032 [==============================] - 729s 706ms/step - loss: 0.1977 - iou_score: 0.7060 - f1-score: 0.8243 - val_loss: 0.6482 - val_iou_score: 0.6811 - val_f1-score: 0.7525 - lr: 1.0000e-07\n",
            "Epoch 40/80\n",
            "1032/1032 [==============================] - 729s 706ms/step - loss: 0.1979 - iou_score: 0.7059 - f1-score: 0.8242 - val_loss: 0.6486 - val_iou_score: 0.6816 - val_f1-score: 0.7530 - lr: 1.0000e-07\n",
            "Epoch 41/80\n",
            "1032/1032 [==============================] - 729s 707ms/step - loss: 0.1976 - iou_score: 0.7062 - f1-score: 0.8244 - val_loss: 0.6482 - val_iou_score: 0.6810 - val_f1-score: 0.7524 - lr: 1.0000e-07\n",
            "Epoch 42/80\n",
            "1032/1032 [==============================] - 728s 706ms/step - loss: 0.1977 - iou_score: 0.7061 - f1-score: 0.8243 - val_loss: 0.6480 - val_iou_score: 0.6823 - val_f1-score: 0.7536 - lr: 1.0000e-07\n",
            "Epoch 43/80\n",
            "1032/1032 [==============================] - 729s 706ms/step - loss: 0.1977 - iou_score: 0.7060 - f1-score: 0.8243 - val_loss: 0.6482 - val_iou_score: 0.6816 - val_f1-score: 0.7530 - lr: 1.0000e-07\n",
            "Epoch 44/80\n",
            "1032/1032 [==============================] - 728s 706ms/step - loss: 0.1973 - iou_score: 0.7067 - f1-score: 0.8247 - val_loss: 0.6478 - val_iou_score: 0.6817 - val_f1-score: 0.7531 - lr: 1.0000e-07\n",
            "Epoch 45/80\n",
            "1032/1032 [==============================] - 710s 688ms/step - loss: 0.1976 - iou_score: 0.7062 - f1-score: 0.8244 - val_loss: 0.6481 - val_iou_score: 0.6811 - val_f1-score: 0.7525 - lr: 1.0000e-07\n",
            "Epoch 46/80\n",
            "1032/1032 [==============================] - 711s 689ms/step - loss: 0.1974 - iou_score: 0.7066 - f1-score: 0.8247 - val_loss: 0.6486 - val_iou_score: 0.6819 - val_f1-score: 0.7533 - lr: 1.0000e-07\n",
            "Epoch 47/80\n",
            "1032/1032 [==============================] - 709s 687ms/step - loss: 0.1975 - iou_score: 0.7064 - f1-score: 0.8245 - val_loss: 0.6481 - val_iou_score: 0.6813 - val_f1-score: 0.7527 - lr: 1.0000e-07\n",
            "Epoch 48/80\n",
            "1032/1032 [==============================] - 704s 682ms/step - loss: 0.1971 - iou_score: 0.7068 - f1-score: 0.8249 - val_loss: 0.6485 - val_iou_score: 0.6822 - val_f1-score: 0.7536 - lr: 1.0000e-07\n",
            "Epoch 49/80\n",
            "1032/1032 [==============================] - 705s 683ms/step - loss: 0.1971 - iou_score: 0.7069 - f1-score: 0.8249 - val_loss: 0.6484 - val_iou_score: 0.6823 - val_f1-score: 0.7536 - lr: 1.0000e-07\n",
            "Epoch 50/80\n",
            "1032/1032 [==============================] - 703s 681ms/step - loss: 0.1973 - iou_score: 0.7067 - f1-score: 0.8248 - val_loss: 0.6482 - val_iou_score: 0.6822 - val_f1-score: 0.7535 - lr: 1.0000e-07\n",
            "Epoch 51/80\n",
            "1032/1032 [==============================] - 703s 681ms/step - loss: 0.1973 - iou_score: 0.7066 - f1-score: 0.8247 - val_loss: 0.6488 - val_iou_score: 0.6819 - val_f1-score: 0.7532 - lr: 1.0000e-07\n",
            "Epoch 52/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1970 - iou_score: 0.7070 - f1-score: 0.8250 - val_loss: 0.6481 - val_iou_score: 0.6813 - val_f1-score: 0.7527 - lr: 1.0000e-07\n",
            "Epoch 53/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1973 - iou_score: 0.7067 - f1-score: 0.8247 - val_loss: 0.6482 - val_iou_score: 0.6812 - val_f1-score: 0.7526 - lr: 1.0000e-07\n",
            "Epoch 54/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1973 - iou_score: 0.7066 - f1-score: 0.8247 - val_loss: 0.6484 - val_iou_score: 0.6818 - val_f1-score: 0.7531 - lr: 1.0000e-07\n",
            "Epoch 55/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1971 - iou_score: 0.7068 - f1-score: 0.8249 - val_loss: 0.6484 - val_iou_score: 0.6822 - val_f1-score: 0.7536 - lr: 1.0000e-07\n",
            "Epoch 56/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1966 - iou_score: 0.7074 - f1-score: 0.8253 - val_loss: 0.6485 - val_iou_score: 0.6817 - val_f1-score: 0.7530 - lr: 1.0000e-07\n",
            "Epoch 57/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1972 - iou_score: 0.7067 - f1-score: 0.8248 - val_loss: 0.6486 - val_iou_score: 0.6824 - val_f1-score: 0.7537 - lr: 1.0000e-07\n",
            "Epoch 58/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1972 - iou_score: 0.7068 - f1-score: 0.8248 - val_loss: 0.6479 - val_iou_score: 0.6819 - val_f1-score: 0.7533 - lr: 1.0000e-07\n",
            "Epoch 59/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1974 - iou_score: 0.7065 - f1-score: 0.8246 - val_loss: 0.6485 - val_iou_score: 0.6821 - val_f1-score: 0.7535 - lr: 1.0000e-07\n",
            "Epoch 60/80\n",
            "1032/1032 [==============================] - 700s 679ms/step - loss: 0.1969 - iou_score: 0.7072 - f1-score: 0.8251 - val_loss: 0.6481 - val_iou_score: 0.6812 - val_f1-score: 0.7526 - lr: 1.0000e-07\n",
            "Epoch 61/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1969 - iou_score: 0.7071 - f1-score: 0.8251 - val_loss: 0.6487 - val_iou_score: 0.6824 - val_f1-score: 0.7537 - lr: 1.0000e-07\n",
            "Epoch 62/80\n",
            "1032/1032 [==============================] - 700s 679ms/step - loss: 0.1972 - iou_score: 0.7067 - f1-score: 0.8248 - val_loss: 0.6485 - val_iou_score: 0.6816 - val_f1-score: 0.7530 - lr: 1.0000e-07\n",
            "Epoch 63/80\n",
            "1032/1032 [==============================] - 700s 679ms/step - loss: 0.1969 - iou_score: 0.7071 - f1-score: 0.8251 - val_loss: 0.6482 - val_iou_score: 0.6827 - val_f1-score: 0.7541 - lr: 1.0000e-07\n",
            "Epoch 64/80\n",
            "1032/1032 [==============================] - 700s 678ms/step - loss: 0.1969 - iou_score: 0.7072 - f1-score: 0.8251 - val_loss: 0.6486 - val_iou_score: 0.6825 - val_f1-score: 0.7538 - lr: 1.0000e-07\n",
            "Epoch 65/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1972 - iou_score: 0.7068 - f1-score: 0.8248 - val_loss: 0.6490 - val_iou_score: 0.6819 - val_f1-score: 0.7532 - lr: 1.0000e-07\n",
            "Epoch 66/80\n",
            "1032/1032 [==============================] - 700s 678ms/step - loss: 0.1966 - iou_score: 0.7075 - f1-score: 0.8253 - val_loss: 0.6481 - val_iou_score: 0.6818 - val_f1-score: 0.7532 - lr: 1.0000e-07\n",
            "Epoch 67/80\n",
            "1032/1032 [==============================] - 700s 679ms/step - loss: 0.1973 - iou_score: 0.7066 - f1-score: 0.8247 - val_loss: 0.6488 - val_iou_score: 0.6823 - val_f1-score: 0.7536 - lr: 1.0000e-07\n",
            "Epoch 68/80\n",
            "1032/1032 [==============================] - 700s 679ms/step - loss: 0.1969 - iou_score: 0.7071 - f1-score: 0.8251 - val_loss: 0.6483 - val_iou_score: 0.6825 - val_f1-score: 0.7539 - lr: 1.0000e-07\n",
            "Epoch 69/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1970 - iou_score: 0.7071 - f1-score: 0.8250 - val_loss: 0.6491 - val_iou_score: 0.6819 - val_f1-score: 0.7532 - lr: 1.0000e-07\n",
            "Epoch 70/80\n",
            "1032/1032 [==============================] - 701s 679ms/step - loss: 0.1970 - iou_score: 0.7070 - f1-score: 0.8250 - val_loss: 0.6481 - val_iou_score: 0.6813 - val_f1-score: 0.7528 - lr: 1.0000e-07\n",
            "Epoch 71/80\n",
            "1032/1032 [==============================] - 697s 675ms/step - loss: 0.1968 - iou_score: 0.7073 - f1-score: 0.8252 - val_loss: 0.6487 - val_iou_score: 0.6820 - val_f1-score: 0.7534 - lr: 1.0000e-07\n",
            "Epoch 72/80\n",
            "1032/1032 [==============================] - 694s 672ms/step - loss: 0.1965 - iou_score: 0.7077 - f1-score: 0.8255 - val_loss: 0.6488 - val_iou_score: 0.6823 - val_f1-score: 0.7536 - lr: 1.0000e-07\n",
            "Epoch 73/80\n",
            "1032/1032 [==============================] - 693s 671ms/step - loss: 0.1966 - iou_score: 0.7076 - f1-score: 0.8254 - val_loss: 0.6483 - val_iou_score: 0.6826 - val_f1-score: 0.7540 - lr: 1.0000e-07\n",
            "Epoch 74/80\n",
            "1032/1032 [==============================] - 691s 670ms/step - loss: 0.1968 - iou_score: 0.7072 - f1-score: 0.8251 - val_loss: 0.6482 - val_iou_score: 0.6823 - val_f1-score: 0.7537 - lr: 1.0000e-07\n",
            "Epoch 75/80\n",
            "1032/1032 [==============================] - 691s 670ms/step - loss: 0.1969 - iou_score: 0.7071 - f1-score: 0.8251 - val_loss: 0.6481 - val_iou_score: 0.6816 - val_f1-score: 0.7530 - lr: 1.0000e-07\n",
            "Epoch 76/80\n",
            "1032/1032 [==============================] - 692s 670ms/step - loss: 0.1968 - iou_score: 0.7073 - f1-score: 0.8252 - val_loss: 0.6488 - val_iou_score: 0.6818 - val_f1-score: 0.7532 - lr: 1.0000e-07\n",
            "Epoch 77/80\n",
            "1032/1032 [==============================] - 692s 670ms/step - loss: 0.1962 - iou_score: 0.7079 - f1-score: 0.8257 - val_loss: 0.6485 - val_iou_score: 0.6821 - val_f1-score: 0.7535 - lr: 1.0000e-07\n",
            "Epoch 78/80\n",
            "1032/1032 [==============================] - 696s 674ms/step - loss: 0.1967 - iou_score: 0.7073 - f1-score: 0.8252 - val_loss: 0.6481 - val_iou_score: 0.6807 - val_f1-score: 0.7522 - lr: 1.0000e-07\n",
            "Epoch 79/80\n",
            "1032/1032 [==============================] - 693s 671ms/step - loss: 0.1967 - iou_score: 0.7074 - f1-score: 0.8253 - val_loss: 0.6484 - val_iou_score: 0.6822 - val_f1-score: 0.7536 - lr: 1.0000e-07\n",
            "Epoch 80/80\n",
            "1032/1032 [==============================] - 692s 670ms/step - loss: 0.1965 - iou_score: 0.7076 - f1-score: 0.8255 - val_loss: 0.6487 - val_iou_score: 0.6825 - val_f1-score: 0.7538 - lr: 1.0000e-07\n",
            "test classification_report \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9952    0.9956    0.9954 327065669\n",
            "           1     0.8179    0.8043    0.8110   8101819\n",
            "\n",
            "    accuracy                         0.9909 335167488\n",
            "   macro avg     0.9065    0.8999    0.9032 335167488\n",
            "weighted avg     0.9909    0.9909    0.9909 335167488\n",
            "\n",
            "train is saved\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9965    0.9964    0.9964 769433685\n",
            "           1     0.8437    0.8499    0.8468  17833899\n",
            "\n",
            "    accuracy                         0.9930 787267584\n",
            "   macro avg     0.9201    0.9231    0.9216 787267584\n",
            "weighted avg     0.9931    0.9930    0.9930 787267584\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_dataset = Dataset(\n",
        "    x_train_dir,\n",
        "    y_train_dir,\n",
        "    classes=CLASSES,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input),\n",
        ")\n",
        "\n",
        "# Dataset for validation images\n",
        "valid_dataset = Dataset(\n",
        "    x_valid_dir,\n",
        "    y_valid_dir,\n",
        "    classes=CLASSES,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input),\n",
        ")\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = Dataloder(valid_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "assert train_dataloader[0][0].shape == (BATCH_SIZE,384, 384,3)\n",
        "assert train_dataloader[0][1].shape == (BATCH_SIZE,384, 384, n_classes)\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(model_name , save_weights_only=True, save_best_only=True, mode='min'),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=True),\n",
        "]\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_dataloader,\n",
        "    steps_per_epoch=len(train_dataloader),\n",
        "    epochs= 80,#EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=valid_dataloader,\n",
        "    validation_steps=len(valid_dataloader),\n",
        ")\n",
        "\n",
        "\n",
        "model.load_weights(model_name)\n",
        "\n",
        "direction = glob.glob(x_valid_dir+'*.png')\n",
        "\n",
        "dataset,d = valid_dataset, 'test_rgb_30/'\n",
        "preds,annos = [], []\n",
        "for i in range(len(dataset)):\n",
        "\n",
        "    image, gt_mask = dataset[i]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model.predict(image).round()\n",
        "    newimg = pr_mask[0,:,:,:]\n",
        "\n",
        "    name = direction[i].replace('test_rgb_30','test_anno_30')\n",
        "\n",
        "    preds.append(newimg[:,:,0])\n",
        "    annos.append(cv2.imread(name)[:,:,0])\n",
        "print('test classification_report ')\n",
        "print(classification_report(np.array(annos).flatten(), np.array(preds).flatten(), labels=[0,1], digits = 4))\n",
        "##################################################################\n",
        "##################################################\n",
        "direction = glob.glob(x_train_dir+'*.png')\n",
        "\n",
        "dataset,d = train_dataset, 'train_rgb_70/'\n",
        "preds,annos = [], []\n",
        "for i in range(len(dataset)):\n",
        "\n",
        "    image, gt_mask = dataset[i]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model.predict(image).round()\n",
        "\n",
        "    newimg = pr_mask[0,:,:,:]\n",
        "    name = direction[i].replace('train_rgb_70','train_anno_70')\n",
        "    preds.append(newimg[:,:,0])\n",
        "    annos.append(cv2.imread(name)[:,:,0])\n",
        "print('train is saved')\n",
        "print(classification_report(np.array(annos).flatten(), np.array(preds).flatten(), labels=[0,1], digits = 4))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "243px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
